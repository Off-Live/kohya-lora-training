output_dir = "/root/output"
logging_dir = "/root/logs"
log_tracker_name = "lora"
save_precision = "fp16"
save_every_n_epochs = 1
save_every_n_steps = 200
max_train_steps = 3000
seed = 0
mixed_precision = "fp16"
log_with = "tensorboard"
optimizer_type = "AdamW8bit"
learning_rate = 5e-5
lr_scheduler = "cosine"
unet_lr = 5e-5
text_encoder_lr = 2.5e-5
network_module = "networks.lora"
network_dim = 8

sample_every_n_steps = 100
sample_sampler = "euler_a"
